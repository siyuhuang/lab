<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Vision and Learning Lab (ViL) at Clemson University</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Vision and Learning Lab (ViL) at Clemson University">
    <meta name="author" content="">
    <!-- Le styles -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="css/theme.css" rel="stylesheet">
    <link href="css/publication.css" rel="stylesheet">
    <!-- Under Construction Starts -->
    <style>
        .under-construction {
            background-color: red;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 24px;
            font-weight: bold;
            position: fixed;
            width: 100%;
            top: 0;
            z-index: 1000;
        }

        body {
            padding-top: 0px; /* Adjust for the fixed banner */
        }

        .navbar .nav {
            display: flex;
            flex-wrap: wrap; /* Allows items to wrap */
            padding-left: 0;
            list-style: none;
            justify-content: center; /* Centers the navigation bar */
        }

        .navbar .nav li {
            flex: 1 1 16%; /* Each navigation item initially takes up 16% width, can adjust */
            text-align: center;
            min-width: 120px; /* Sets a minimum width to allow wrapping on smaller screens */
            border-bottom: 1px solid #ddd; /* Adds a horizontal line below each navigation item */
        }

        .navbar .nav a {
            display: block;
            padding: 10px 15px;
            text-decoration: none;
            color: black;
        }

        .navbar .nav a:hover {
            background-color: #f8f9fa;
            color: #007bff;
        }

        @media (max-width: 768px) {
            .navbar .nav li {
                flex: 1 1 30%; /* Displays two navigation items per row on smaller screens */
            }
        }
    </style>
    <!-- Under Construction Ends -->
</head>
<body>
<div class="container">
    <header class="jumbotron subhead" id="overview">
        <h1>Vision and Learning Lab</h1>
        <p class="lead"> Clemson University </p>
    </header>
    <div class="masthead">
        <div class="navbar">
            <div class="navbar-inner">
                <div class="container">
                    <ul class="nav">
                        <li><a href="index.html">Home</a></li>
                        <li><a href="people.html">People</a></li>
                        <!-- <li><a href="research.html">Research</a></li> -->
                        <li class="active"><a href="#">Publication</a></li>
                        <li><a href="teaching.html">Teaching</a></li>
                        <!-- <li><a href="fun.html">Lab Fun</a></li> -->
                        <li><a href="contact.html">Join Us</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </div>

    <div class="row-fluid">

        <div class="span3 bs-docs-sidebar" id="navparent">
            <ul class="nav nav-list bs-docs-sidenav" data-spy="affix" data-offset-top="200" data-offset-bottom="260">
                <li><a href="#"> Years </a></li>
                <li><a class="subhead" href="#2025"> 2025 </a></li>
                <li><a class="subhead" href="#2024"> 2024 </a></li>
                <li><a class="subhead" href="#2023"> 2023 </a></li>
                <li><a class="subhead" href="#2022"> 2022 </a></li>
                <li><a class="subhead" href="#2021"> 2021 </a></li>
                <li><a class="subhead" href="#2020"> 2020 and earlier </a></li>
            </ul>
        </div>

        <div class="span8">
            <section id="published">
                <!--<div class="page-header">
                   <h3>Journal Publications</h3>
                </div>-->

                </section>
                <section id="2025">
                    <h3>2025</h3>

                     <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/bs.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>BÃ©zier Splatting for Fast and Differentiable Vector Graphics Rendering</h4>
                            <p class="authors">
                                Xi Liu, Chaoyi Zhou, Nanxuan Zhao, Siyu Huang
                            </p>
                            <p class="publication"><em>NeurIPS</em>, 2025 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://xiliu8006.github.io/Bezier_splatting_project/" target="_blank">Project
                                    Website</a> |
                                <a href="https://arxiv.org/abs/2503.16424" target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>
                    
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/autoal.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>AutoAL: Automated Active Learning with Differentiable Query Strategy Search</h4>
                            <p class="authors">
                                Yifeng Wang, Xueying Zhan, Siyu Huang
                            </p>
                            <p class="publication"><em>ICML</em>, 2025 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2410.13853" target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>
                    
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/softshadow.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>SoftShadow: Leveraging Soft Masks for Penumbra-Aware Shadow Removal</h4>
                            <p class="authors">
                                Xinrui Wang, Lanqing Guo, Xiyu Wang, Siyu Huang, Bihan Wen
                            </p>
                            <p class="publication"><em>CVPR</em>, 2025 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2409.07041" target="_blank">PDF</a> |
                                <a href="https://github.com/Xinrui014/SoftShadow" target="_blank">Code</a>
                            </div>
                        </div>
                     </div>
                        
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/lrf.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Latent Radiance Fields with 3D-aware 2D Representations</h4>
                            <p class="authors">
                                Chaoyi Zhou*,
                                Xi Liu*,
                                Feng Luo,
                                Siyu Huang
                            </p>
                            <p class="publication"><em>ICLR</em>, 2025 &nbsp <font
                                    color="red"></font></p>
                            <div class="links">
                                <a href="https://latent-radiance-field.github.io/LRF/" target="_blank">Project
                                    Website</a> |
                                <a href="https://arxiv.org/abs/2502.09613" target="_blank">PDF</a> |
                                <a href="https://github.com/ChaoyiZh/latent-radiance-field" target="_blank">Code</a>
                            </div>
                        </div>

                    </div>

                </section>
                <section id="2024">
                    <h3>2024</h3>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/3dgs_enhancer.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D
                                Diffusion Priors</h4>
                            <p class="authors">
                                Xi Liu*,
                                Chaoyi Zhou*,
                                Siyu Huang
                            </p>
                            <p class="publication"><em>NeurIPS</em>, 2024 &nbsp <font
                                    color="red"><strong>(Spotlight)</strong></font></p>
                            <div class="links">
                                <a href="https://xiliu8006.github.io/3DGS-Enhancer-project/" target="_blank">Project
                                    Website</a> |
                                <a href="https://arxiv.org/pdf/2410.16266" target="_blank">PDF</a> |
                                <a href="https://github.com/xiliu8006/3DGS-Enhancer" target="_blank">Code</a>
                            </div>
                        </div>

                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/makescale.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Make a Cheap Scaling: A Self-Cascade Diffusion Model for Higher-Resolution
                                Adaptation</h4>
                            <p class="authors">
                                Lanqing Guo, Yingqing He, Haoxin Chen, Menghan Xia, Xiaodong Cun, Yufei Wang, Siyu
                                Huang, Yong Zhang, Xintao Wang, Qifeng Chen, Ying Shan, Bihan Wen
                            </p>
                            <p class="publication"><em>ECCV</em>, 2024 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://guolanqing.github.io/Self-Cascade/" target="_blank">Project Website</a> |
                                <a href="https://arxiv.org/abs/2402.10491" target="_blank">PDF</a> |
                                <a href="https://github.com/GuoLanqing/Self-Cascade" target="_blank">Code</a>
                            </div>
                        </div>

                    See a full publication list on <a href="https://siyuhuang.github.io/#Publications" target="_blank">https://siyuhuang.github.io/#publications</a>

                    <!-- </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/fundus2video.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Fundus2Video: Cross-Modal Angiography Video Generation from Static Fundus Photography
                                with Clinical Knowledge Guidance</h4>
                            <p class="authors">
                                Weiyi Zhang, Siyu Huang, Jiancheng Yang, Ruoyu Chen, Zongyuan Ge, Yingfeng Zheng, Danli
                                Shi, Mingguang He
                            </p>
                            <p class="publication"><em>MICCAI</em>, 2024 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <!-- Add links if available, such as Project Website, PDF, Code -->
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/mtpret.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>MTPret: Improving X-ray Image Analytics with Multi-Task Pre-training</h4>
                            <p class="authors">
                                Weibin Liao, Qingzhong Wang, Xuhong Li, Yi Liu, Zeyu Chen, Siyu Huang, Dejing Dou, Yanwu
                                Xu, Haoyi Xiong
                            </p>
                            <p class="publication"><em>IEEE Transactions on Artificial Intelligence (TAI)</em>, 2024
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <!-- Add links if available, such as Project Website, PDF, Code -->
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/gc_gan.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Learning Gaze-aware Compositional GAN from Limited Annotations</h4>
                            <p class="authors">
                                Nerea Aranjuelo Ansa, Siyu Huang, Ignacio Arganda-Carreras, Luis Unzueta Irurtia, Oihana
                                Otaegui Madurga, Hanspeter Pfister, Donglai Wei
                            </p>
                            <p class="publication"><em>ACM Symposium of Eye Tracking Research & Applications (ETRA)</em>,
                                2024 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ETRA-2024-Learning Gaze-aware Compositional GAN from Limited Annotations.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/naranjuelo/GC-GAN" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/s3_tta.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>S3-TTA: Scale-Style Selection for Test-Time Augmentation in Biomedical Image
                                Segmentation</h4>
                            <p class="authors">
                                Kangxian Xie, Siyu Huang, Sebastian Andres Cajas Ordonez, Hanspeter Pfister, Donglai Wei
                            </p>
                            <p class="publication"><em>IEEE International Symposium on Biomedical Imaging (ISBI)</em>,
                                2024 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2310.16783" target="_blank">PDF</a> |
                                <a href="https://github.com/kangxian97/S3-TTA" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>


                </section>

                <section id="2023">
                    <h3>2023</h3>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/robust_denoising.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Towards Robust Image Denoising via Flow-based Joint Image and Noise Model</h4>
                            <p class="authors">
                                Lanqing Guo, Siyu Huang, Haosen Liu, and Bihan Wen
                            </p>
                            <p class="publication"><em>IEEE Transactions on Circuits and Systems for Video Technology
                                (TCSVT)</em>, 2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TCSVT-2023-Towards_Robust_Image_Denoising_via_Flow-based_Joint_Image_and_Noise_Model.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/contre.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>ContRE: A Complementary Measure for Robustness Evaluation of Deep Networks via
                                Contrastive Examples</h4>
                            <p class="authors">
                                Xuhong Li, Xuanyu Wu, Linghe Kong, Xiao Zhang, Siyu Huang, Dejing Dou, and Haoyi Xiong
                            </p>
                            <p class="publication"><em>IEEE International Conference on Data Mining (ICDM)</em>, 2023
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ICDM-2023-ContRE_A_Complementary_Measure_for_Robustness_Evaluation_of_Deep_Networks_via_Contrastive_Examples.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/latent_space_anchoring.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Domain-Scalable Unpaired Image Translation via Latent Space Anchoring</h4>
                            <p class="authors">
                                Siyu Huang*, Jie An*, Donglai Wei, Zudi Lin, Jiebo Luo, Hanspeter Pfister
                            </p>
                            <p class="publication"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence
                                (TPAMI)</em>, 2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TPAMI-2023-Domain-Scalable_Unpaired_Image_Translation_Via_Latent_Space_Anchoring.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/siyuhuang/Latent-Space-Anchoring" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/cysgan.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>3D Domain Adaptive Instance Segmentation via Cyclic Segmentation GANs</h4>
                            <p class="authors">
                                Leander Lauenburg, Zudi Lin, Ruihan Zhang, Marcia dos Santos, Siyu Huang, Ignacio
                                Arganda-Carreras, Edward S. Boyden, Hanspeter Pfister, Donglai Wei
                            </p>
                            <p class="publication"><em>IEEE Journal of Biomedical and Health Informatics (JBHI)</em>,
                                2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/JBHI-2023-3D_Domain_Adaptive_Instance_Segmentation_Via_Cyclic_Segmentation_GANs.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://connectomics-bazaar.github.io/proj/CySGAN/index.html" target="_blank">Project</a>
                                |
                                <a href="https://github.com/zudi-lin/pytorch_connectomics/tree/master/projects/CySGAN"
                                   target="_blank">Code</a> |
                                <a href="https://docs.google.com/forms/d/e/1FAIpQLSfO_iuzA6r0-VTBI-wq0i7Q230-vAaNhJ3spiMAALd_r9oFOg/viewform"
                                   target="_blank">Dataset</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/quantart.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>QuantArt: Quantizing Image Style Transfer Towards High Visual Fidelity</h4>
                            <p class="authors">
                                Siyu Huang*, Jie An*, Donglai Wei, Jiebo Luo, Hanspeter Pfister
                            </p>
                            <p class="publication"><em>IEEE Conference on Computer Vision and Pattern Recognition
                                (CVPR)</em>, 2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2212.10431" target="_blank">PDF</a> |
                                <a href="https://siyuhuang.github.io/papers/CVPR23-QuantArt-slides.pdf" target="_blank">Slides</a>
                                |
                                <a href="https://github.com/siyuhuang/QuantArt" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/shadowdiffusion.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>ShadowDiffusion: When Degradation Prior Meets Diffusion Model for Shadow Removal</h4>
                            <p class="authors">
                                Lanqing Guo, Chong Wang, Wenhan Yang, Siyu Huang, Yufei Wang, Hanspeter Pfister, Bihan
                                Wen
                            </p>
                            <p class="publication"><em>IEEE Conference on Computer Vision and Pattern Recognition
                                (CVPR)</em>, 2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2212.04711" target="_blank">PDF</a> |
                                <a href="https://github.com/GuoLanqing/ShadowDiffusion" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/csval.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Making Your First Choice: To Address Cold Start Problem in Vision Active Learning</h4>
                            <p class="authors">
                                Liangyu Chen, Yutong Bai, Siyu Huang, Yongyi Lu, Bihan Wen, Alan Yuille, Zongwei Zhou
                            </p>
                            <p class="publication"><em>Medical Imaging with Deep Learning (MIDL)</em>, 2023 &nbsp <font
                                    color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2210.02442" target="_blank">PDF</a> |
                                <a href="https://github.com/cliangyu/CSVAL" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/cross_model_consensus.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Cross-Model Consensus of Explanations and Beyond for Image Classification Models: An
                                Empirical Study</h4>
                            <p class="authors">
                                Xuhong Li, Haoyi Xiong, Siyu Huang, Shilei Ji, Dejing Dou
                            </p>
                            <p class="publication"><em>Machine Learning, European Conference on Machine Learning 2022
                                journal track (MLJ)</em>, 2023 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/MLJ-2023-Cross%E2%80%91model%20consensus%20of%20explanations%20and%20beyond%20for%20image%20classifcation%20models%20an%20empirical%20study.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/PaddlePaddle/InterpretDL/blob/master/interpretdl/interpreter/consensus.py"
                                   target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/shadowformer.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>ShadowFormer: Global Context Helps Shadow Removal</h4>
                            <p class="authors">
                                Lanqing Guo, Siyu Huang, Ding Liu, Hao Cheng, Bihan Wen
                            </p>
                            <p class="publication"><em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2023
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://arxiv.org/abs/2302.01650" target="_blank">PDF</a> |
                                <a href="https://github.com/GuoLanqing/ShadowFormer" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>


                </section>

                <section id="2022">
                    <h3>2022</h3>


                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/tod.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Temporal Output Discrepancy for Loss Estimation-based Active Learning</h4>
                            <p class="authors">
                                Siyu Huang, Tianyang Wang, Haoyi Xiong, Bihan Wen, Jun Huan, Dejing Dou
                            </p>
                            <p class="publication"><em>IEEE Transactions on Neural Networks and Learning Systems
                                (TNNLS)</em>, 2022 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TNNLS-2022-Temporal_Output_Discrepancy_for_Loss_Estimation-Based_Active_Learning.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/siyuhuang/TOD" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/muscle.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>MUSCLE: Multi-task Self-supervised Continual Learning to Pre-train Deep Models for X-ray
                                Images of Multiple Body Parts</h4>
                            <p class="authors">
                                Weibin Liao, Haoyi Xiong, Qingzhong Wang, Yan Mo, Xuhong Li, Yi Liu, Zeyu Chen, Siyu
                                Huang, Dejing Dou
                            </p>
                            <p class="publication"><em>Medical Image Computing and Computer Assisted Intervention
                                (MICCAI)</em>, 2022 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/MICCAI-2022-MUSCLE-%20Multi-task%20Self-supervised%20Continual%20Learning%20to%20Pre-train%20Deep%20Models%20for%20X-Ray%20Images%20of%20Multiple%20Body%20Parts.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/bhpl.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>A Unified Framework for Bidirectional Prototype Learning from Contaminated Faces across
                                Heterogeneous Domains</h4>
                            <p class="authors">
                                Meng Pang, Binghui Wang, Siyu Huang, Yiu-ming Cheung, Bihan Wen
                            </p>
                            <p class="publication"><em>IEEE Transactions on Information Forensics and Security
                                (TIFS)</em>, 2022 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TIFS-2022-A_Unified_Framework_for_Bidirectional_Prototype_Learning_from_Contaminated_Faces_across_Heterogeneous_Domains.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/PangMeng92/BHPL_Codes" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/style_projection.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Parameter-Free Style Projection for Arbitrary Style Transfer</h4>
                            <p class="authors">
                                Siyu Huang, Haoyi Xiong, Tianyang Wang, Bihan Wen, Qingzhong Wang, Zeyu Chen, Jun Huan,
                                Dejing Dou
                            </p>
                            <p class="publication"><em>International Conference on Acoustics, Speech, and Signal
                                Processing (ICASSP)</em>, 2022 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ICASSP-2022-Parameter-Free_Style_Projection_for_Arbitrary_Image_Style_Transfer.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/PaddlePaddle/PaddleHub/tree/dbca09ae78b5387ebe3b49f37ce88de45d41d26a/hub_module/modules/image/style_transfer/stylepro_artistic"
                                   target="_blank">Code</a> |
                                <a href="https://www.paddlepaddle.org.cn/hubdetail?name=stylepro_artistic"
                                   target="_blank">Official PaddleHub</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/bmnas.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>BM-NAS: Bilevel Multimodal Neural Architecture Search</h4>
                            <p class="authors">
                                Yihang Yin, Siyu Huang, Xiang Zhang
                            </p>

                            <p class="publication"><em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                                &nbsp <font
                                        color="red"><strong>(Oral)</strong></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/AAAI-2022-BM-NAS-Bilevel%20Multimodal%20Neural%20Architecture%20Search.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://www.youtube.com/watch?v=EGZu5bOi_M4" target="_blank">Video</a> |
                                <a href="https://github.com/Somedaywilldo/BM-NAS" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/autogcl.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>AutoGCL: Automated Graph Contrastive Learning via Learnable View Generators</h4>
                            <p class="authors">
                                Yihang Yin, Qingzhong Wang, Siyu Huang, Haoyi Xiong, Xiang Zhang
                            </p>
                            <p class="publication"><em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/AAAI-2022-AutoGCL-Automated%20Graph%20Contrastive%20Learning%20via%20Learnable%20View%20Generators.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://www.youtube.com/watch?v=37iavACXCIw" target="_blank">Video</a> |
                                <a href="https://github.com/Somedaywilldo/AutoGCL" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/boosting_al.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Boosting Active Learning via Improving Test Performance</h4>
                            <p class="authors">
                                Tianyang Wang, Xingjian Li, Pengkun Yang, Guosheng Hu, Xiangrui Zeng, Siyu Huang,
                                Cheng-Zhong Xu, Min Xu
                            </p>
                            <p class="publication"><em>AAAI Conference on Artificial Intelligence (AAAI)</em>, 2022
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/AAAI-2022-Boosting%20Active%20Learning%20via%20Improving%20Test%20Performance.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/xulabs/aitom/tree/master/aitom/ml/active_learning/al_gradnorm"
                                   target="_blank">Code</a>
                            </div>
                        </div>
                    </div>


                </section>

                <section id="2021">
                    <h3>2021</h3>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/temporal_output_discrepancy.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Semi-Supervised Active Learning with Temporal Output Discrepancy</h4>
                            <p class="authors">
                                Siyu Huang, Tianyang Wang, Haoyi Xiong, Jun Huan, Dejing Dou
                            </p>
                            <p class="publication"><em>International Conference on Computer Vision (ICCV)</em>, 2021
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ICCV-2021-Semi-Supervised%20Active%20Learning%20with%20Temporal%20Output%20Discrepancy.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://siyuhuang.github.io/papers/ICCV-2021-Semi-Supervised%20Active%20Learning%20with%20Temporal%20Output%20Discrepancy-supp.pdf"
                                   target="_blank">Supp</a> |
                                <a href="https://siyuhuang.github.io/papers/ICCV21-poster.pdf"
                                   target="_blank">Poster</a> |
                                <a href="https://siyuhuang.github.io/papers/ICCV21-slides.pdf"
                                   target="_blank">Slides</a> |
                                <a href="https://www.youtube.com/watch?v=aDuHa9eu3gQ" target="_blank">Video</a> |
                                <a href="https://github.com/siyuhuang/TOD" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/rellie.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>ReLLIE: Deep Reinforcement Learning for Customized Low-Light Image Enhancement</h4>
                            <p class="authors">
                                Rongkai Zhang, Lanqing Guo, Siyu Huang, Bihan Wen
                            </p>
                            <p class="publication"><em>ACM International Conference on Multimedia (ACM MM)</em>, 2021
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ACM%20MM-2021-ReLLIE%20Deep%20Reinforcement%20Learning%20for%20Customized%20Low-Light%20Image%20Enhancement.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/GuoLanqing/ReLLIE" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/covid19_response.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>An Investigation of Containment Measure Implementation and Public Responses to the
                                COVID-19 Pandemic in Mainland China</h4>
                            <p class="authors">
                                Ji Liu, Haoyi Xiong, Xiakai Wang, Jizhou Huang, Qiaojun Li, Tongtong Huang, Siyu Huang,
                                Haifeng Wang, Dejing Dou
                            </p>
                            <p class="publication"><em>IEEE International Conference on Digital Health (ICDH)</em>, 2021
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://ieeexplore.ieee.org/abstract/document/9581178" target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/artflow.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>ArtFlow: Unbiased Image Style Transfer via Reversible Neural Flows</h4>
                            <p class="authors">
                                Jie An*, Siyu Huang*, Yibing Song, Dejing Dou, Wei Liu, Jiebo Luo
                            </p>
                            <p class="publication"><em>IEEE Conference on Computer Vision and Pattern Recognition
                                (CVPR)</em>, 2021 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/CVPR-2021-ArtFlow%20Unbiased%20Image%20Style%20Transfer%20via%20Reversible%20Neural%20Flows.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://siyuhuang.github.io/papers/CVPR-2021-ArtFlow%20Unbiased%20Image%20Style%20Transfer%20via%20Reversible%20Neural%20Flows-supp.pdf"
                                   target="_blank">Supp</a> |
                                <a href="https://github.com/pkuanjie/ArtFlow" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>


                </section>

                <section id="2020">
                    <h3>2020 and earlier</h3>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/dual_low_rank.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Dual Low-Rank Multimodal Fusion</h4>
                            <p class="authors">
                                Tao Jin*, Siyu Huang*, Yingming Li, Zhongfei Zhang
                            </p>
                            <p class="publication"><em>Findings of the Association for Computational Linguistics: EMNLP
                                (EMNLP Findings)</em>, 2020 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/EMNLP-Findings-2020-Dual%20Low-Rank%20Multimodal%20Fusion.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/neighbours_matter.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Neighbours Matter: Image Captioning with Similar Images</h4>
                            <p class="authors">
                                Qingzhong Wang, Jiuniu Wang, Antoni Chan, Siyu Huang, Haoyi Xiong, Xingjian Li, Dejing
                                Dou
                            </p>
                            <p class="publication"><em>British Machine Vision Conference (BMVC)</em>, 2020 &nbsp <font
                                    color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/BMVC-2020-Neighbours%20Matter-%20Image%20Captioning%20with%20Similar%20Images.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/pose_stylizer.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Generating Person Images with Appearance-aware Pose Stylizer</h4>
                            <p class="authors">
                                Siyu Huang, Haoyi Xiong, Zhi-Qi Cheng, Qingzhong Wang, Xingran Zhou, Bihan Wen, Jun
                                Huan, Dejing Dou
                            </p>
                            <p class="publication"><em>International Joint Conference on Artificial Intelligence
                                (IJCAI)</em>, 2020 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/IJCAI-2020-Generating%20Person%20Images%20with%20Appearance-aware%20Pose%20Stylizer.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/siyuhuang/PoseStylizer" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/sbat.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>SBAT: Video Captioning with Sparse Boundary-Aware Transformer</h4>
                            <p class="authors">
                                Tao Jin, Siyu Huang, Ming Chen, Yingming Li, Zhongfei Zhang
                            </p>
                            <p class="publication"><em>International Joint Conference on Artificial Intelligence
                                (IJCAI)</em>, 2020 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/IJCAI-2020-SBAT%20Video%20Captioning%20with%20Sparse%20Boundary-Aware%20Transformer.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/stacked_pooling.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Stacked Pooling for Boosting Scale Invariance of Crowd Counting</h4>
                            <p class="authors">
                                Siyu Huang, Xi Li, Zhi-Qi Cheng, Zhongfei Zhang, Alexander Hauptmann
                            </p>
                            <p class="publication"><em>International Conference on Acoustics, Speech, and Signal
                                Processing (ICASSP)</em>, 2020 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ICASSP-2020-STACKED%20POOLING%20FOR%20BOOSTING%20SCALE%20INVARIANCE%20OF%20CROWD%20COUNTING.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/siyuhuang/crowdcount-stackpool" target="_blank">Code</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/low_rank_hoca.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning</h4>
                            <p class="authors">
                                Tao Jin, Siyu Huang*, Yingming Li, Zhongfei Zhang
                            </p>
                            <p class="publication"><em>Conference on Empirical Methods in Natural Language Processing
                                (EMNLP)</em>, 2019 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/EMNLP-2019-Low-Rank%20HOCA.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/text_guided_synthesis.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Text Guided Person Image Synthesis</h4>
                            <p class="authors">
                                Xingran Zhou, Siyu Huang*, Bin Li, Yingming Li, Jiachen Li, Zhongfei Zhang
                            </p>
                            <p class="publication"><em>IEEE Conference on Computer Vision and Pattern Recognition
                                (CVPR)</em>, 2019 &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/CVPR-2019-Text%20Guided%20Person%20Image%20Synthesis.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://siyuhuang.github.io/papers/CVPR-2019-Text%20Guided%20Person%20Image%20Synthesis-supp.pdf"
                                   target="_blank">Supp</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/user_ranking.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>User-Ranking Video Summarization with Multi-Stage Spatio-Temporal Representation</h4>
                            <p class="authors">
                                Siyu Huang, Xi Li, Zhongfei Zhang, Fei Wu, Junwei Han
                            </p>
                            <p class="publication"><em>IEEE Transactions on Image Processing (TIP)</em>, 2019 &nbsp
                                <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TIP-2019-User-Ranking%20Video%20Summarization%20with%20Multi-Stage%20Spatio-Temporal%20Representation.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://drive.google.com/open?id=1yVRRM6DFQRlK0UFKADjwLxbRbCdSQyDF"
                                   target="_blank">Demo</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/physical_equation.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Perceiving Physical Equation by Observing Visual Scenarios</h4>
                            <p class="authors">
                                Siyu Huang*, Zhi-Qi Cheng*, Xi Li, Xiao Wu, Zhongfei Zhang, Alexander Hauptmann
                            </p>
                            <p class="publication"><em>NeurIPS Workshop on Modeling the Physical World</em>, 2018 &nbsp
                                <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/NIPSW-2018-Perceiving%20Physical%20Equation%20by%20Observing%20Visual%20Scenarios.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/tvt.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>TVT: Two-View Transformer Network for Video Captioning</h4>
                            <p class="authors">
                                Ming Chen, Yingming Li, Zhongfei Zhang, Siyu Huang
                            </p>
                            <p class="publication"><em>Asian Conference on Machine Learning (ACML)</em>, 2018 &nbsp
                                <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ACML-2018-Two-View%20Transformer%20Network%20for%20Video%20Captioning.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>
                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/gnas.png" alt="Publication Image" class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>GNAS: A Greedy Neural Architecture Search Method for Multi-Attribute Learning</h4>
                            <p class="authors">
                                Siyu Huang, Xi Li, Zhi-Qi Cheng, Zhongfei Zhang, Alexander Hauptmann
                            </p>
                            <p class="publication"><em>ACM International Conference on Multimedia (ACM MM)</em>, 2018
                                <b>(Oral)</b> &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ACM%20MM-2018-GNAS%20A%20Greedy%20Neural%20Architecture%20Search%20Method%20for%20Multi-attribute%20Learning.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://siyuhuang.github.io/papers/gnas_oral.pdf" target="_blank">Slides</a> |
                                <a href="https://siyuhuang.github.io/papers/gnas_poster.pdf" target="_blank">Poster</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/learning_to_transfer.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Learning to Transfer: Generalizable Attribute Learning with Multitask Neural Model
                                Search</h4>
                            <p class="authors">
                                Zhi-Qi Cheng, Xiao Wu, Siyu Huang, Jun-Xiu Li, Alexander Hauptmann, Qiang Peng
                            </p>
                            <p class="publication"><em>ACM International Conference on Multimedia (ACM MM)</em>, 2018
                                &nbsp <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/ACM%20MM-2018-Learning%20to%20Transfer%20Generalizable%20Attribute%20Learning%20with%20Multitask%20Neural%20Model%20Search.pdf"
                                   target="_blank">PDF</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/body_structure_aware.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Body Structure Aware Deep Crowd Counting</h4>
                            <p class="authors">
                                Siyu Huang, Xi Li, Zhongfei Zhang, Fei Wu, Shenghua Gao, Rongrong Ji, Junwei Han
                            </p>
                            <p class="publication"><em>IEEE Transactions on Image Processing (TIP)</em>, 2018 &nbsp
                                <font color="red"></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TIP-2018-Body%20Structure%20Aware%20Deep%20Crowd%20Counting.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://drive.google.com/open?id=1X86WV6pnGD7pYYSI5Sxwj2ooI6jrm-z2"
                                   target="_blank">Demo</a>
                            </div>
                        </div>
                    </div>

                    <div class="row-fliud paper">
                        <div class="span4">
                            <img src="images/pub_imgs/visual_path_prediction.png" alt="Publication Image"
                                 class="publication-image">
                        </div>
                        <div class="span8">
                            <h4>Deep Learning Driven Visual Path Prediction From a Single Image</h4>
                            <p class="authors">
                                Siyu Huang, Xi Li, Zhongfei Zhang, Zhouzhou He, Fei Wu, Wei Liu, Jinhui Tang, Yueting
                                Zhuang
                            </p>
                            <p class="publication"><em>IEEE Transactions on Image Processing (TIP)</em>, 2016
                                &nbsp <font
                                        color="red"><strong>(Oral)</strong></font></p>
                            <div class="links">
                                <a href="https://siyuhuang.github.io/papers/TIP-2016-Deep%20Learning%20Driven%20Visual%20Path%20Prediction%20from%20a%20Single%20Image%20.pdf"
                                   target="_blank">PDF</a> |
                                <a href="https://github.com/siyuhuang/Visual-Path-Prediction-TIP-2016/" target="_blank">Dataset</a>
                            </div>
                        </div>
                    </div> -->


                </section>
            </section>
        </div>
    </div>
</div>


<footer id="footer">
    <p>Â© 2024 Vision and Learning Lab @ Clemson University</p>
</footer>
<!-- Le javascript
   ================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<script src="js/jquery-1.9.1.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script>
    $(document).ready(function () {
        $(document.body).scrollspy({
            target: "#navparent"
        });
    });

</script>
</body>
</html>
